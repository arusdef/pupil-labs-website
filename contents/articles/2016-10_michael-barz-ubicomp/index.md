---
title: Michael Barz's demo at UBICOMP
date: Mon Oct 17 2016 15:59:02 GMT+0700 (ICT)
author: Pupil Dev Team
subtitle: "Michael Barz's demonstration used Pupil Capture with custom plugin for gaze-guided object classification using deep neural networks for attention-based computing..."
featured_img_thumb: "../../../../media/images/blog/theinformation_2016.png"
---

Michael Barz's demonstration used Pupil Capture with custom plugin for gaze-guided object classification using deep neural networks for attention-based computing. 


<div class="Feature-video-container-16by9">
	<iframe class="Feature-video" src="https://www.youtube.com/embed/AW1zg4IPcfI" frameborder="0" allowfullscreen></iframe>
</div>


Recent advances in eye tracking technologies opened the way to design novel attention-based user interfaces. A system that incorporates the gaze signal and the egocentric camera of the eye tracker to identify the objects the user focuses at for constructing episodic memories of egocentric events in real-time.

For more information check out the [published paper](http://dl.acm.org/citation.cfm?doid=2968219.2971389).

Check out the [academic citation spreadsheet](https://docs.google.com/spreadsheets/d/1ZD6HDbjzrtRNB4VB0b7GFMaXVGKZYeI0zBOBEEPwvBI/edit#gid=0) for more academic projects on Pupil.