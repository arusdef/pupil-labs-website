---
title: Gaze-guided object classification with Pupil
date: Mon Oct 17 2016 15:59:02 GMT+0700 (ICT)
author: Pupil Dev Team
subtitle: "Michael Barz and Daniel Sonntag use Pupil to create a gaze-guided object classification system..."
featured_img_thumb: "../../../../media/images/blog/thumb/michael_ubicomp.png"
---

Michael Barz and Daniel Sonntag use Pupil to create a gaze-guided object classification system. Check out the video below for a demonstration.

<div class="Feature-video-container-16by9">
	<iframe class="Feature-video" src="https://www.youtube.com/embed/AW1zg4IPcfI" frameborder="0" allowfullscreen></iframe>
</div>

An excerpt from their UBICOMP 2016 demo abstract below

<blockquote cite="http://dl.acm.org/citation.cfm?doid=2968219.2971389"> "... Recent advances in eye tracking technologies opened the way to design novel attention-based user interfaces. A system that incorporates the gaze signal and the egocentric camera of the eye tracker to identify the objects the user focuses at for constructing episodic memories of egocentric events in real-time."
</blockquote>

We are really excited about their work. It is a great demonstration of how one can use Pupil and the plugin architecture as a foundation for novel research.

Check out their full [demo paper here](http://dl.acm.org/citation.cfm?doid=2968219.2971389).

If you use Pupil in your research and have published work, please send us a note. We would love to include it in our list of [work that cites Pupil](https://docs.google.com/spreadsheets/d/1ZD6HDbjzrtRNB4VB0b7GFMaXVGKZYeI0zBOBEEPwvBI/).